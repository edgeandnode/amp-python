# generated by datamodel-codegen:
#   filename:  admin.spec.json
#   timestamp: 2025-11-06T23:57:02+00:00

from __future__ import annotations

from datetime import datetime
from enum import Enum
from typing import Annotated, Any, Optional, Union

from pydantic import BaseModel, Field


class Dataset(BaseModel):
    """
    Dataset information

    Represents a dataset tag with its namespace, name, and version.
    """

    name: str
    """
    Dataset name
    """
    namespace: str
    """
    Dataset namespace
    """
    version: str
    """
    Version tag
    """


class DatasetInfo(BaseModel):
    """
    Detailed dataset information
    """

    kind: str
    """
    Dataset kind
    """
    manifest_hash: str
    """
    Manifest hash
    """
    name: str
    """
    Dataset name
    """
    namespace: str
    """
    Dataset namespace
    """
    revision: str
    """
    Revision requested
    """


class DatasetSummary(BaseModel):
    """
    Summary information for a single dataset
    """

    latest_version: Optional[str] = None
    """
    Latest semantic version (if any)
    """
    name: str
    """
    Dataset name
    """
    namespace: str
    """
    Dataset namespace
    """
    versions: list[str]
    """
    All semantic versions (sorted descending)
    """


class DatasetsResponse(BaseModel):
    """
    Response for listing all datasets
    """

    datasets: list[DatasetSummary]
    """
    List of all datasets across all namespaces
    """


class DeployResponse(BaseModel):
    """
    Response for deploy operation
    """

    job_id: int
    """
    The ID of the scheduled dump job (64-bit integer)
    """


class EndBlock(BaseModel):
    """
    End block configuration for API requests.

    Determines when the dump process should stop extracting blocks.
    Accepts the following values:

    - `null` (or omitted): Continuous dumping - never stops, keeps extracting new blocks as they arrive
    - `"latest"`: Stop at the latest available block at the time the dump starts
    - A positive number as a string (e.g., `"1000000"`): Stop at the specified absolute block number
    - A negative number as a string (e.g., `"-100"`): Stop at (latest block - N), useful for staying N
      blocks behind the chain tip

    Note: This is a simple wrapper around Optional[str] for documentation purposes.
    """

    value: Optional[str] = None


class ErrorResponse(BaseModel):
    """
    Standard error response returned by the API

    This struct represents error information returned in HTTP error responses.
    It provides structured error details including a machine-readable error code
    and human-readable message.

    ## Error Code Conventions
    - Error codes use SCREAMING_SNAKE_CASE (e.g., `DATASET_NOT_FOUND`)
    - Codes are stable and can be relied upon programmatically
    - Messages may change and should only be used for display/logging

    ## Example JSON Response
    ```json
    {
      "error_code": "DATASET_NOT_FOUND",
      "error_message": "dataset 'eth_mainnet' version '1.0.0' not found"
    }
    ```
    """

    error_code: str
    """
    Machine-readable error code in SCREAMING_SNAKE_CASE format

    Error codes are stable across API versions and should be used
    for programmatic error handling. Examples: `INVALID_SELECTOR`,
    `DATASET_NOT_FOUND`, `METADATA_DB_ERROR`
    """
    error_message: str
    """
    Human-readable error message

    Messages provide detailed context about the error but may change
    over time. Use `error_code` for programmatic decisions.
    """


class FileInfo(BaseModel):
    """
    File information returned by the API

    This struct represents file metadata from the database in a format
    suitable for API responses. It contains all the essential information
    about Parquet files and their associated metadata within locations.
    """

    file_name: str
    """
    Name of the file (e.g., "blocks_0000000000_0000099999.parquet")
    """
    id: int
    """
    Unique identifier for this file (64-bit integer)
    """
    location_id: int
    """
    Location ID this file belongs to (64-bit integer)
    """
    metadata: Any
    """
    Parquet file metadata as JSON containing schema and statistics
    """
    object_e_tag: Optional[str] = None
    """
    ETag of the file object for caching and version identification
    """
    object_size: Optional[int] = None
    """
    Size of the file object in bytes
    """
    object_version: Optional[str] = None
    """
    Version identifier of the file object in the storage system
    """
    url: str
    """
    Base location URL (e.g., "s3://bucket/path/") - combine with file_name for full file URL
    """


class FileListInfo(BaseModel):
    """
    Minimal file information for location file listings

    This struct represents essential file metadata for list endpoints,
    containing only the most relevant information needed for file browsing
    within a location context.
    """

    file_name: str
    """
    Name of the file (e.g., "blocks_0000000000_0000099999.parquet")
    """
    id: int
    """
    Unique identifier for this file (64-bit integer)
    """
    object_size: Optional[int] = None
    """
    Size of the file object in bytes
    """


class JobInfo(BaseModel):
    """
    Job information returned by the API

    This struct represents job metadata in a format suitable for API responses.
    It contains essential information about a job without exposing internal
    database implementation details.
    """

    descriptor: Any
    """
    Job descriptor containing job-specific parameters as JSON
    """
    id: int
    """
    Unique identifier for this job (64-bit integer)
    """
    node_id: str
    """
    ID of the worker node this job is scheduled for
    """
    status: str
    """
    Current status of the job (Scheduled, Running, Completed, Stopped, Failed, etc.)
    """


class JobsResponse(BaseModel):
    """
    API response containing job information
    """

    jobs: list[JobInfo]
    """
    List of jobs
    """
    next_cursor: Optional[int] = None
    """
    Cursor for the next page of results (None if no more results)
    """


class LocationFilesResponse(BaseModel):
    """
    Collection response for location file listings

    This response structure provides paginated file data with
    cursor-based pagination support for efficient traversal.
    """

    files: list[FileListInfo]
    """
    List of files in this page with minimal information
    """
    next_cursor: Optional[int] = None
    """
    Cursor for the next page of results - use as last_file_id in next request (None if no more results)
    """


class LocationInfo(BaseModel):
    """
    Location information returned by the API

    This struct represents location metadata from the database in a format
    suitable for API responses. It contains all the essential information
    about where dataset table data is stored.
    """

    active: bool
    """
    Whether this location is currently active for queries
    """
    dataset: str
    """
    Name of the dataset this location belongs to
    """
    dataset_version: str
    """
    Version of the dataset using semantic versioning (e.g., "1.0.0", or empty string for unversioned)
    """
    id: int
    """
    Unique identifier for this location (64-bit integer)
    """
    table: str
    """
    Name of the table within the dataset (e.g., "blocks", "transactions")
    """
    url: str
    """
    Full URL to the storage location (e.g., "s3://bucket/path/table.parquet", "file:///local/path/table.parquet")
    """
    writer: Optional[int] = None
    """
    Writer job ID (64-bit integer, if one exists)
    """


class LocationInfoWithDetails(BaseModel):
    """
    Location information with writer job details
    """

    active: bool
    """
    Whether this location is currently active for queries
    """
    dataset: str
    """
    Name of the dataset this location belongs to
    """
    dataset_version: str
    """
    Version of the dataset using semantic versioning (e.g., "1.0.0", or empty string for unversioned)
    """
    id: int
    """
    Unique identifier for this location (64-bit integer)
    """
    table: str
    """
    Name of the table within the dataset (e.g., "blocks", "transactions")
    """
    url: str
    """
    Full URL to the storage location (e.g., "s3://bucket/path/table.parquet", "file:///local/path/table.parquet")
    """
    writer: Optional[JobInfo] = None


class LocationsResponse(BaseModel):
    """
    API response containing location information

    This response structure provides paginated location data with
    cursor-based pagination support for efficient traversal.
    """

    locations: list[LocationInfo]
    """
    List of locations in this page
    """
    next_cursor: Optional[int] = None
    """
    Cursor for the next page of results (None if no more results)
    """


class ManifestDatasetsResponse(BaseModel):
    """
    Response for listing datasets using a manifest
    """

    datasets: list[Dataset]
    """
    List of datasets using this manifest
    """
    hash: str
    """
    Manifest hash
    """


class ManifestResponse(BaseModel):
    """
    Response wrapper for manifest content
    """


class OutputSchemaRequest(BaseModel):
    """
    Request payload for output schema analysis

    Contains the SQL query to analyze and optional configuration flags.
    """

    is_sql_dataset: Optional[bool] = None
    """
    Whether this is a SQL dataset (affects block number field inclusion)

    When true, a special block number field is prepended to the schema.
    This field tracks the block number for each row in SQL datasets.
    """
    sql_query: str
    """
    The SQL query to analyze for output schema determination
    """


class OutputSchemaResponse(BaseModel):
    """
    Response returned by the output schema endpoint

    Contains the determined schema and list of networks referenced by the query.
    """

    networks: list[str]
    """
    List of networks referenced by the query

    Contains the network names of all datasets/tables referenced
    in the SQL query (e.g., "mainnet", "polygon", etc.).
    """
    schema_: Annotated[Any, Field(alias='schema')]
    """
    The output schema for the SQL query

    Describes the structure and types of columns that will be returned
    when executing the provided SQL query against the dataset.
    """


class ProviderInfo(BaseModel):
    """
    Provider information used for both API requests and responses

    This struct represents provider metadata and configuration in a format
    suitable for both creating providers (POST requests) and retrieving them
    (GET responses). It includes the complete provider configuration.

    ## Security Note

    The `rest` field contains the full provider configuration. Ensure that
    sensitive information like API keys and tokens are not stored in the
    provider configuration if this data will be exposed through APIs.
    """

    kind: str
    """
    The type of provider (e.g., "evm-rpc", "firehose")
    """
    name: str
    """
    The name/identifier of the provider
    """
    network: str
    """
    The blockchain network (e.g., "mainnet", "goerli", "polygon")
    """


class ProvidersResponse(BaseModel):
    """
    API response containing complete provider information

    This response structure provides all provider configurations
    available in the system, including their full configuration details.
    """

    providers: list[ProviderInfo]
    """
    List of all provider configurations with complete configuration details
    """


class PruneResponse(BaseModel):
    """
    Response payload for manifest pruning operation

    Contains the count of successfully deleted orphaned manifests.
    """

    deleted_count: Annotated[int, Field(ge=0)]
    """
    Number of orphaned manifests successfully deleted
    """


class RegisterManifestResponse(BaseModel):
    """
    Response payload for manifest registration

    Contains the computed hash of the registered manifest.
    """

    hash: str
    """
    The computed content hash of the manifest (used as unique identifier)
    """


class Manifest(BaseModel):
    """
    A manifest hash (64-character SHA-256 hex string)
    """

    hash: Annotated[str, Field(max_length=64, min_length=64, pattern='[0-9a-fA-F]{64}')]


class RegisterRequest(BaseModel):
    """
    Request payload for dataset registration

    Contains the dataset namespace, name, version, and manifest.
    The manifest will be registered (or validated if hash provided), linked to the dataset,
    and optionally tagged with a semantic version.
    """

    manifest: Union[Manifest, dict[str, Any]]
    """
    Either a manifest hash (64-char hex string) or full manifest JSON content
    """
    name: str
    """
    Name of the dataset to be registered (validated identifier format)
    """
    namespace: str
    """
    Namespace for the dataset (validated identifier format)
    """
    version: Optional[str] = None
    """
    Optional version of the dataset to register using semantic versioning (e.g., "1.0.0").

    If omitted, only the manifest linking and "dev" tag update are performed.
    If provided, the manifest is also tagged with this semantic version, and "latest" tag is
    updated if this version is higher than the current latest.
    """


class SpecialTags(BaseModel):
    """
    Special tags pointing to versions or hashes
    """

    dev: Optional[str] = None
    """
    Dev tag pointing to manifest hash (if any)
    """
    latest: Optional[str] = None
    """
    Latest semantic version (if any)
    """


class String(Enum):
    """
    Status filter options for job deletion
    """

    Terminal = 'Terminal'
    Completed = 'Completed'
    Stopped = 'Stopped'
    Error = 'Error'


class Value(BaseModel):
    """Generic value wrapper for Any type"""

    value: Any


class VersionInfo(BaseModel):
    """
    Version information
    """

    created_at: str
    """
    When this version was created
    """
    manifest_hash: str
    """
    Manifest hash for this version
    """
    updated_at: str
    """
    When this version was last updated
    """
    version: str
    """
    Semantic version
    """


class VersionsResponse(BaseModel):
    """
    Response for listing dataset versions
    """

    name: str
    """
    Dataset name
    """
    namespace: str
    """
    Dataset namespace
    """
    special_tags: SpecialTags
    """
    Special tags (latest and dev)
    """
    versions: list[VersionInfo]
    """
    List of semantic versions (sorted descending)
    """


class WorkerInfo(BaseModel):
    """
    Worker information returned by the API

    Contains basic identification and liveness information for a worker node.
    This is a lightweight summary view suitable for list endpoints.
    """

    heartbeat_at: Annotated[datetime, Field(examples=['2025-01-15T17:20:15.456789Z'])]
    """
    Last heartbeat timestamp (RFC3339 format)

    The most recent time this worker sent a heartbeat signal. Workers send
    periodic heartbeats to indicate they are alive and processing work.
    A stale heartbeat indicates the worker may be down or unreachable.
    """
    node_id: Annotated[
        str,
        Field(
            examples=[
                'worker-01h2xcejqtf2nbrexx3vqjhp41',
                'indexer-node-1',
                'amp_worker.prod',
            ],
            pattern='^[a-zA-Z][a-zA-Z0-9_\\-\\.]*$',
        ),
    ]
    """
    Unique identifier for the worker node

    A persistent identifier that uniquely identifies this worker across registrations
    and heartbeats. Used for tracking and managing individual worker instances.

    Must start with a letter and contain only alphanumeric characters, underscores,
    hyphens, and dots.
    """


class WorkerMetadata(BaseModel):
    """
    Worker metadata containing build and version information

    This struct captures comprehensive build and version details for a worker node,
    enabling tracking of deployed versions and troubleshooting version-specific issues.
    """

    build_date: Annotated[
        datetime,
        Field(examples=['2025-01-15T15:45:30Z', '2025-01-15T10:45:30-05:00', 'unknown']),
    ]
    """
    Date and time when the worker binary was built (RFC3339 format)

    The timestamp when the build process completed. May differ from commit
    timestamp, especially for CI/CD builds or local development builds.

    Returns "unknown" if build date is not available.
    """
    commit_sha: Annotated[str, Field(examples=['8b065bde9c1a2f3e4d5c6b7a8e9f0a1b2c3d4e5f', 'unknown'])]
    """
    Full Git commit SHA (40-character hexadecimal)

    The complete SHA-1 hash of the commit from which this worker was built.
    Used for precise version identification and source code correlation.

    Returns "unknown" if commit information is not available.
    """
    commit_timestamp: Annotated[
        datetime,
        Field(examples=['2025-01-15T14:30:00Z', '2025-01-15T09:30:00-05:00', 'unknown']),
    ]
    """
    Timestamp when the commit was created (RFC3339 format)

    The date and time when the source code commit was made to the repository.
    Helps correlate worker versions with development timeline.

    Returns "unknown" if timestamp is not available.
    """
    version: Annotated[
        str,
        Field(
            examples=[
                'v0.0.22',
                'v0.0.22-dirty',
                'v0.0.22-15-g8b065bde',
                'v0.0.22-15-g8b065bde-dirty',
                'unknown',
            ]
        ),
    ]
    """
    Version string including git describe output

    Format: `v{major}.{minor}.{patch}[-{commits_since_tag}-g{short_sha}][-dirty]`

    The "-dirty" suffix indicates uncommitted changes in the working directory.
    Returns "unknown" if version information is not available.
    """


class WorkersResponse(BaseModel):
    """
    Collection response for worker listings

    Contains a list of all registered workers in the system with their
    basic information including node identifiers and last heartbeat times.
    """

    workers: list[WorkerInfo]
    """
    List of all registered workers

    Each worker entry contains the node ID and last heartbeat timestamp.
    Workers are ordered by their database insertion order.
    """


class DeployRequest(BaseModel):
    """
    Request for deploying a dataset
    """

    end_block: Optional[EndBlock] = None
    """
    The end block configuration for the deployment

    Supports multiple modes:
    - `null` or omitted: Continuous dumping (never stops)
    - `"latest"`: Stop at the latest available block
    - `<number>`: Stop at specific block number (e.g., `1000000`)
    - `<negative number>`: Stop N blocks before latest (e.g., `-100` means latest - 100)

    If not specified, defaults to continuous mode.
    """
    parallelism: Annotated[Optional[int], Field(ge=0)] = None
    """
    Number of parallel workers to run

    Each worker will be responsible for an equal number of blocks.
    For example, if extracting blocks 0-10,000,000 with parallelism=10,
    each worker will handle a contiguous section of 1 million blocks.

    Only applicable to raw datasets (EVM RPC, Firehose, etc.).
    Derived datasets ignore this parameter.

    Defaults to 1 if not specified.
    """


class WorkerDetailResponse(BaseModel):
    """
    Detailed worker information returned by the API

    Contains comprehensive information about a worker node including its identity,
    lifecycle timestamps, and build metadata. This response enables monitoring of
    worker health, version tracking, and operational status.
    """

    created_at: Annotated[datetime, Field(examples=['2025-01-15T14:30:00.123456Z'])]
    """
    Timestamp when the worker was first created in the system (RFC3339 format)

    The initial registration time of this worker. This timestamp never changes
    and represents when the worker first appeared in the system.
    """
    heartbeat_at: Annotated[datetime, Field(examples=['2025-01-15T17:20:15.456789Z'])]
    """
    Last heartbeat timestamp (RFC3339 format)

    The most recent time this worker sent a heartbeat signal. Workers send
    periodic heartbeats to indicate they are alive and processing work.
    A stale heartbeat indicates the worker may be down or unreachable.
    """
    info: WorkerMetadata
    """
    Worker metadata including version and build information

    Contains detailed build and version information for this worker,
    including git version, commit details, and build timestamps.
    """
    node_id: Annotated[
        str,
        Field(
            examples=[
                'worker-01h2xcejqtf2nbrexx3vqjhp41',
                'indexer-node-1',
                'amp_worker.prod',
            ],
            pattern='^[a-zA-Z][a-zA-Z0-9_\\-\\.]*$',
        ),
    ]
    """
    Unique identifier for the worker node

    A persistent identifier that uniquely identifies this worker across registrations
    and heartbeats. Used for tracking and managing individual worker instances.

    Must start with a letter and contain only alphanumeric characters, underscores,
    hyphens, and dots.
    """
    registered_at: Annotated[datetime, Field(examples=['2025-01-15T16:45:30.789012Z'])]
    """
    Timestamp when the worker last registered (RFC3339 format)

    Updated each time a worker re-registers with the system. Workers typically
    re-register on startup or reconnection. Use this to track worker restarts.
    """
