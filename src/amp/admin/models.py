# generated by datamodel-codegen:
#   filename:  admin.spec.json
#   timestamp: 2025-12-13T12:27:34+00:00

from __future__ import annotations

from enum import Enum
from typing import Annotated, Any, Optional, Union

from pydantic import AwareDatetime, BaseModel, Field, RootModel


class Dataset(BaseModel):
    """
    Dataset information

    Represents a dataset tag with its namespace, name, and version.
    """

    name: str
    """
    Dataset name
    """
    namespace: str
    """
    Dataset namespace
    """
    version: str
    """
    Version tag
    """


class DatasetInfo(BaseModel):
    """
    Detailed dataset information
    """

    kind: str
    """
    Dataset kind
    """
    manifest_hash: str
    """
    Manifest hash
    """
    name: str
    """
    Dataset name
    """
    namespace: str
    """
    Dataset namespace
    """
    revision: str
    """
    Revision requested
    """


class DatasetSummary(BaseModel):
    """
    Summary information for a single dataset
    """

    latest_version: Optional[str] = None
    """
    Latest semantic version (if any)
    """
    name: str
    """
    Dataset name
    """
    namespace: str
    """
    Dataset namespace
    """
    versions: list[str]
    """
    All semantic versions (sorted descending)
    """


class DatasetsResponse(BaseModel):
    """
    Response for listing all datasets
    """

    datasets: list[DatasetSummary]
    """
    List of all datasets across all namespaces
    """


class DeployResponse(BaseModel):
    """
    Response for deploy operation
    """

    job_id: int
    """
    The ID of the scheduled dump job (64-bit integer)
    """


class EndBlock(RootModel[Optional[str]]):
    root: Optional[str]
    """
    End block configuration for API requests.

    Determines when the dump process should stop extracting blocks.
    Accepts the following values:

    - `null` (or omitted): Continuous dumping - never stops, keeps extracting new blocks as they arrive
    - `"latest"`: Stop at the latest available block at the time the dump starts
    - A positive number as a string (e.g., `"1000000"`): Stop at the specified absolute block number
    - A negative number as a string (e.g., `"-100"`): Stop at (latest block - N), useful for staying N blocks behind the chain tip
    """


class ErrorResponse(BaseModel):
    """
    Standard error response returned by the API

    This struct represents error information returned in HTTP error responses.
    It provides structured error details including a machine-readable error code
    and human-readable message.

    ## Error Code Conventions
    - Error codes use SCREAMING_SNAKE_CASE (e.g., `DATASET_NOT_FOUND`)
    - Codes are stable and can be relied upon programmatically
    - Messages may change and should only be used for display/logging

    ## Example JSON Response
    ```json
    {
      "error_code": "DATASET_NOT_FOUND",
      "error_message": "dataset 'eth_mainnet' version '1.0.0' not found"
    }
    ```
    """

    error_code: str
    """
    Machine-readable error code in SCREAMING_SNAKE_CASE format

    Error codes are stable across API versions and should be used
    for programmatic error handling. Examples: `INVALID_SELECTOR`,
    `DATASET_NOT_FOUND`, `METADATA_DB_ERROR`
    """
    error_message: str
    """
    Human-readable error message

    Messages provide detailed context about the error but may change
    over time. Use `error_code` for programmatic decisions.
    """


class FileInfo(BaseModel):
    """
    File information returned by the API

    This struct represents file metadata from the database in a format
    suitable for API responses. It contains all the essential information
    about Parquet files and their associated metadata within locations.
    """

    file_name: str
    """
    Name of the file (e.g., "blocks_0000000000_0000099999.parquet")
    """
    id: int
    """
    Unique identifier for this file (64-bit integer)
    """
    location_id: int
    """
    Location ID this file belongs to (64-bit integer)
    """
    metadata: Any
    """
    Parquet file metadata as JSON containing schema and statistics
    """
    object_e_tag: Optional[str] = None
    """
    ETag of the file object for caching and version identification
    """
    object_size: Optional[int] = None
    """
    Size of the file object in bytes
    """
    object_version: Optional[str] = None
    """
    Version identifier of the file object in the storage system
    """
    url: str
    """
    Base location URL (e.g., "s3://bucket/path/") - combine with file_name for full file URL
    """


class JobInfo(BaseModel):
    """
    Represents job information for the API response
    """

    created_at: str
    """
    Job creation timestamp in ISO 8601 / RFC 3339 format
    """
    descriptor: Any
    """
    Job descriptor containing job-specific parameters as JSON
    """
    id: int
    """
    Unique identifier for the job (64-bit integer)
    """
    node_id: str
    """
    ID of the worker node this job is scheduled for
    """
    status: str
    """
    Current status of the job (Scheduled, Running, Completed, Stopped, Failed, etc.)
    """
    updated_at: str
    """
    Job last update timestamp in ISO 8601 / RFC 3339 format
    """


class JobsResponse(BaseModel):
    """
    API response containing job information
    """

    jobs: list[JobInfo]
    """
    List of jobs
    """
    next_cursor: Optional[int] = None
    """
    Cursor for the next page of results (None if no more results)
    """


class ManifestDatasetsResponse(BaseModel):
    """
    Response for listing datasets using a manifest
    """

    datasets: list[Dataset]
    """
    List of datasets using this manifest
    """
    hash: str
    """
    Manifest hash
    """


class ManifestInfo(BaseModel):
    """
    Summary information for a single manifest
    """

    dataset_count: Annotated[int, Field(ge=0)]
    """
    Number of datasets using this manifest
    """
    hash: str
    """
    Content-addressable hash (SHA-256)
    """


class ManifestResponse(BaseModel):
    """
    Response wrapper for manifest content
    """


class ManifestsResponse(BaseModel):
    """
    Response for listing all manifests
    """

    manifests: list[ManifestInfo]
    """
    List of all manifests in the system
    """


class ProviderInfo(BaseModel):
    """
    Provider information used for both API requests and responses

    This struct represents provider metadata and configuration in a format
    suitable for both creating providers (POST requests) and retrieving them
    (GET responses). It includes the complete provider configuration.

    ## Security Note

    The `rest` field contains the full provider configuration. Ensure that
    sensitive information like API keys and tokens are not stored in the
    provider configuration if this data will be exposed through APIs.
    """

    kind: str
    """
    The type of provider (e.g., "evm-rpc", "firehose")
    """
    name: str
    """
    The name/identifier of the provider
    """
    network: str
    """
    The blockchain network (e.g., "mainnet", "goerli", "polygon")
    """


class ProvidersResponse(BaseModel):
    """
    API response containing complete provider information

    This response structure provides all provider configurations
    available in the system, including their full configuration details.
    """

    providers: list[ProviderInfo]
    """
    List of all provider configurations with complete configuration details
    """


class PruneResponse(BaseModel):
    """
    Response payload for manifest pruning operation

    Contains the count of successfully deleted orphaned manifests.
    """

    deleted_count: Annotated[int, Field(ge=0)]
    """
    Number of orphaned manifests successfully deleted
    """


class RegisterManifestResponse(BaseModel):
    """
    Response payload for manifest registration

    Contains the computed hash of the registered manifest.
    """

    hash: str
    """
    The computed content hash of the manifest (used as unique identifier)
    """


class Manifest(RootModel[str]):
    root: Annotated[str, Field(max_length=64, min_length=64, pattern='[0-9a-fA-F]{64}')]
    """
    A manifest hash (64-character SHA-256 hex string)
    """


class RegisterRequest(BaseModel):
    """
    Request payload for dataset registration

    Contains the dataset namespace, name, version, and manifest.
    The manifest will be registered (or validated if hash provided), linked to the dataset,
    and optionally tagged with a semantic version.
    """

    manifest: Union[Manifest, dict[str, Any]]
    """
    Either a manifest hash (64-char hex string) or full manifest JSON content
    """
    name: str
    """
    Name of the dataset to be registered (validated identifier format)
    """
    namespace: str
    """
    Namespace for the dataset (validated identifier format)
    """
    version: Optional[str] = None
    """
    Optional version of the dataset to register using semantic versioning (e.g., "1.0.0").

    If omitted, only the manifest linking and "dev" tag update are performed.
    If provided, the manifest is also tagged with this semantic version, and "latest" tag is
    updated if this version is higher than the current latest.
    """


class RestoredTableInfo(BaseModel):
    """
    Information about a restored physical table
    """

    location_id: int
    """
    Unique location ID assigned in the metadata database
    """
    table_name: str
    """
    Name of the table within the dataset
    """
    url: str
    """
    Full URL to the storage location
    """


class SchemaRequest(BaseModel):
    """
    Request for schema analysis with dependencies, tables, and functions
    """

    dependencies: Optional[dict[str, str]] = None
    """
    External dataset dependencies mapped by alias

    Maps alias names to dataset references (namespace/name@version or namespace/name@hash).
    These aliases are used in SQL queries to reference external datasets.
    Symbolic references like "latest" or "dev" are not allowed.
    """
    functions: Optional[dict[str, Any]] = None
    """
    User-defined function definitions mapped by function name

    Maps function names to their complete definitions including input/output types
    and implementation source code. These functions can be referenced in SQL queries
    as bare function calls (e.g., `my_function(args)` without dataset qualification).

    At least one of `tables` or `functions` must be provided.

    Function names must follow DataFusion UDF identifier rules:
    - Start with a letter (a-z, A-Z) or underscore (_)
    - Contain only letters, digits (0-9), underscores (_), and dollar signs ($)
    - Maximum length of 255 bytes
    """
    tables: Optional[dict[str, str]] = None
    """
    Table definitions mapped by table name

    Each table is defined by a SQL query that may reference
    tables from dependencies using the alias names.
    """


class SpecialTags(BaseModel):
    """
    Special tags pointing to versions or hashes
    """

    dev: Optional[str] = None
    """
    Dev tag pointing to manifest hash (if any)
    """
    latest: Optional[str] = None
    """
    Latest semantic version (if any)
    """


class String(Enum):
    """
    Status filter options for job deletion
    """

    Terminal = 'Terminal'
    Completed = 'Completed'
    Stopped = 'Stopped'
    Error = 'Error'


class TableSchemaWithNetworks(BaseModel):
    """
    Table schema with associated networks

    Contains the output schema for a table and the list of networks referenced by its query.
    """

    networks: list[str]
    """
    List of networks referenced by this table's query

    Contains the network names of all datasets/tables referenced
    in this specific table's SQL query (e.g., "mainnet", "polygon", etc.).
    """
    schema_: Annotated[Any, Field(alias='schema')]
    """
    The output schema for the table

    Describes the structure and types of columns that will be returned
    when executing the SQL query for this table.
    """


class Value(RootModel[Any]):
    root: Any


class VersionInfo(BaseModel):
    """
    Version information
    """

    created_at: str
    """
    When this version was created
    """
    manifest_hash: str
    """
    Manifest hash for this version
    """
    updated_at: str
    """
    When this version was last updated
    """
    version: str
    """
    Semantic version
    """


class VersionsResponse(BaseModel):
    """
    Response for listing dataset versions
    """

    name: str
    """
    Dataset name
    """
    namespace: str
    """
    Dataset namespace
    """
    special_tags: SpecialTags
    """
    Special tags (latest and dev)
    """
    versions: list[VersionInfo]
    """
    List of semantic versions (sorted descending)
    """


class WorkerInfo(BaseModel):
    """
    Worker information returned by the API

    Contains basic identification and liveness information for a worker node.
    This is a lightweight summary view suitable for list endpoints.
    """

    heartbeat_at: Annotated[
        AwareDatetime, Field(examples=['2025-01-15T17:20:15.456789Z'])
    ]
    """
    Last heartbeat timestamp (RFC3339 format)

    The most recent time this worker sent a heartbeat signal. Workers send
    periodic heartbeats to indicate they are alive and processing work.
    A stale heartbeat indicates the worker may be down or unreachable.
    """
    node_id: Annotated[
        str,
        Field(
            examples=[
                'worker-01h2xcejqtf2nbrexx3vqjhp41',
                'indexer-node-1',
                'amp_worker.prod',
            ],
            pattern='^[a-zA-Z][a-zA-Z0-9_\\-\\.]*$',
        ),
    ]
    """
    Unique identifier for the worker node

    A persistent identifier that uniquely identifies this worker across registrations
    and heartbeats. Used for tracking and managing individual worker instances.

    Must start with a letter and contain only alphanumeric characters, underscores,
    hyphens, and dots.
    """


class WorkerMetadata(BaseModel):
    """
    Worker metadata containing build and version information

    This struct captures comprehensive build and version details for a worker node,
    enabling tracking of deployed versions and troubleshooting version-specific issues.
    """

    build_date: Annotated[
        AwareDatetime,
        Field(
            examples=['2025-01-15T15:45:30Z', '2025-01-15T10:45:30-05:00', 'unknown']
        ),
    ]
    """
    Date and time when the worker binary was built (RFC3339 format)

    The timestamp when the build process completed. May differ from commit
    timestamp, especially for CI/CD builds or local development builds.

    Returns "unknown" if build date is not available.
    """
    commit_sha: Annotated[
        str, Field(examples=['8b065bde9c1a2f3e4d5c6b7a8e9f0a1b2c3d4e5f', 'unknown'])
    ]
    """
    Full Git commit SHA (40-character hexadecimal)

    The complete SHA-1 hash of the commit from which this worker was built.
    Used for precise version identification and source code correlation.

    Returns "unknown" if commit information is not available.
    """
    commit_timestamp: Annotated[
        AwareDatetime,
        Field(
            examples=['2025-01-15T14:30:00Z', '2025-01-15T09:30:00-05:00', 'unknown']
        ),
    ]
    """
    Timestamp when the commit was created (RFC3339 format)

    The date and time when the source code commit was made to the repository.
    Helps correlate worker versions with development timeline.

    Returns "unknown" if timestamp is not available.
    """
    version: Annotated[
        str,
        Field(
            examples=[
                'v0.0.22',
                'v0.0.22-dirty',
                'v0.0.22-15-g8b065bde',
                'v0.0.22-15-g8b065bde-dirty',
                'unknown',
            ]
        ),
    ]
    """
    Version string including git describe output

    Format: `v{major}.{minor}.{patch}[-{commits_since_tag}-g{short_sha}][-dirty]`

    The "-dirty" suffix indicates uncommitted changes in the working directory.
    Returns "unknown" if version information is not available.
    """


class WorkersResponse(BaseModel):
    """
    Collection response for worker listings

    Contains a list of all registered workers in the system with their
    basic information including node identifiers and last heartbeat times.
    """

    workers: list[WorkerInfo]
    """
    List of all registered workers

    Each worker entry contains the node ID and last heartbeat timestamp.
    Workers are ordered by their database insertion order.
    """


class DeployRequest(BaseModel):
    """
    Request for deploying a dataset
    """

    end_block: Optional[EndBlock] = None
    """
    The end block configuration for the deployment

    Supports multiple modes:
    - `null` or omitted: Continuous dumping (never stops)
    - `"latest"`: Stop at the latest available block
    - `<number>`: Stop at specific block number (e.g., `1000000`)
    - `<negative number>`: Stop N blocks before latest (e.g., `-100` means latest - 100)

    If not specified, defaults to continuous mode.
    """
    parallelism: Annotated[Optional[int], Field(ge=0)] = None
    """
    Number of parallel workers to run

    Each worker will be responsible for an equal number of blocks.
    For example, if extracting blocks 0-10,000,000 with parallelism=10,
    each worker will handle a contiguous section of 1 million blocks.

    Only applicable to raw datasets (EVM RPC, Firehose, etc.).
    Derived datasets ignore this parameter.

    Defaults to 1 if not specified.
    """
    worker_id: Optional[str] = None
    """
    Optional worker ID to assign the job to

    If specified, the job will be assigned to this specific worker.
    If not specified, a worker will be selected randomly from available workers.

    The worker must be active (has sent heartbeats recently) for the deployment to succeed.
    """


class RestoreResponse(BaseModel):
    """
    Response for restore operation
    """

    tables: list[RestoredTableInfo]
    """
    List of restored physical tables
    """


class SchemaResponse(BaseModel):
    """
    Response returned by the schema endpoint

    Contains schemas and networks for one or more tables.
    """

    schemas: dict[str, TableSchemaWithNetworks]
    """
    Schemas for each table

    Maps table names to their schemas and networks.
    Contains one entry per table definition.
    """


class WorkerDetailResponse(BaseModel):
    """
    Detailed worker information returned by the API

    Contains comprehensive information about a worker node including its identity,
    lifecycle timestamps, and build metadata. This response enables monitoring of
    worker health, version tracking, and operational status.
    """

    created_at: Annotated[
        AwareDatetime, Field(examples=['2025-01-15T14:30:00.123456Z'])
    ]
    """
    Timestamp when the worker was first created in the system (RFC3339 format)

    The initial registration time of this worker. This timestamp never changes
    and represents when the worker first appeared in the system.
    """
    heartbeat_at: Annotated[
        AwareDatetime, Field(examples=['2025-01-15T17:20:15.456789Z'])
    ]
    """
    Last heartbeat timestamp (RFC3339 format)

    The most recent time this worker sent a heartbeat signal. Workers send
    periodic heartbeats to indicate they are alive and processing work.
    A stale heartbeat indicates the worker may be down or unreachable.
    """
    info: WorkerMetadata
    """
    Worker metadata including version and build information

    Contains detailed build and version information for this worker,
    including git version, commit details, and build timestamps.
    """
    node_id: Annotated[
        str,
        Field(
            examples=[
                'worker-01h2xcejqtf2nbrexx3vqjhp41',
                'indexer-node-1',
                'amp_worker.prod',
            ],
            pattern='^[a-zA-Z][a-zA-Z0-9_\\-\\.]*$',
        ),
    ]
    """
    Unique identifier for the worker node

    A persistent identifier that uniquely identifies this worker across registrations
    and heartbeats. Used for tracking and managing individual worker instances.

    Must start with a letter and contain only alphanumeric characters, underscores,
    hyphens, and dots.
    """
    registered_at: Annotated[
        AwareDatetime, Field(examples=['2025-01-15T16:45:30.789012Z'])
    ]
    """
    Timestamp when the worker last registered (RFC3339 format)

    Updated each time a worker re-registers with the system. Workers typically
    re-register on startup or reconnection. Use this to track worker restarts.
    """
